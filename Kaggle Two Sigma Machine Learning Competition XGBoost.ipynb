{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn import *\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc678e17b4431bacdc3a5a2ad3b638c57f7f5797"},"cell_type":"code","source":"#(whole_market_train, whole_news_train) = env.get_training_data()\n(market_train, news_train) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d3120d88accacb88d2df7fedd3d47274cace337"},"cell_type":"code","source":"#market_train=whole_market_train.head(50000)\n#news_train=whole_news_train.head(100000)\ntype(market_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d4e9739b2cd52925df80cfc2160144dc1097874"},"cell_type":"code","source":"news_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4f8ca598247b054dd7b29d471b8505946394381"},"cell_type":"code","source":"import datetime\n\nmarket_train = market_train.loc[market_train['time'].dt.date>=datetime.date(2009,1,1)]\nnews_train = news_train.loc[news_train['time'].dt.date>=datetime.date(2009,1,1)]\n\n\nmarket_train['close_open_ratio'] = np.abs(market_train['close']/market_train['open'])\nthreshold = 0.5\nprint('In %i lines price increases by 50%% or more in a day' %(market_train['close_open_ratio']>=1.5).sum())\nprint('In %i lines price decreases by 50%% or more in a day' %(market_train['close_open_ratio']<=0.5).sum())\n\n\nmarket_train = market_train.loc[market_train['close_open_ratio'] < 1.5]\nmarket_train = market_train.loc[market_train['close_open_ratio'] > 0.5]\nmarket_train = market_train.drop(columns=['close_open_ratio'])\n\n\ncolumn_market = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolumn_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\nfor i in range(len(column_raw)):\n    market_train[column_market[i]] = market_train[column_market[i]].fillna(market_train[column_raw[i]])\n    \n    \nprint('Removing outliers ...')\ncolumn_return = column_market + column_raw + ['returnsOpenNextMktres10']\norig_len = market_train.shape[0]\nfor column in column_return:\n    market_train = market_train.loc[market_train[column]>=-2]\n    market_train = market_train.loc[market_train[column]<=2]\nnew_len = market_train.shape[0]\nrmv_len = np.abs(orig_len-new_len)\nprint('There were %i lines removed' %rmv_len)\n\n\n\nprint('Removing strange data ...')\norig_len = market_train.shape[0]\nmarket_train = market_train[~market_train['assetCode'].isin(['PGN.N','EBRYY.OB'])]\n#market_train = market_train[~market_train['assetName'].isin(['Unknown'])]\nnew_len = market_train.shape[0]\nrmv_len = np.abs(orig_len-new_len)\nprint('There were %i lines removed' %rmv_len)\n\n\n\n# Function to remove outliers\ndef remove_outliers(data_frame, column_list, low=0.02, high=0.98):\n    for column in column_list:\n        this_column = data_frame[column]\n        quant_df = this_column.quantile([low,high])\n        low_limit = quant_df[low]\n        high_limit = quant_df[high]\n        data_frame[column] = data_frame[column].clip(lower=low_limit, upper=high_limit)\n    return data_frame\n\n\n\n# Remove outlier\ncolumns_outlier = ['takeSequence', 'bodySize', 'sentenceCount', 'wordCount', 'sentimentWordCount', 'firstMentionSentence','noveltyCount12H',\\\n                  'noveltyCount24H', 'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H', 'volumeCounts24H',\\\n                  'volumeCounts3D','volumeCounts5D','volumeCounts7D']\nprint('Clipping news outliers ...')\nnews_train = remove_outliers(news_train, columns_outlier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f26e940a8c450cf9561f6c3c3a5d9ccb1623878a"},"cell_type":"code","source":"def preprocess_news(news_train):\n    drop_list = [\n        'audiences', 'subjects', 'assetName',\n        'headline'\n    ]\n    news_train.drop(drop_list, axis=1, inplace=True)\n    \n    # Factorize categorical columns\n    for col in ['headlineTag', 'provider', 'sourceId']:\n        news_train[col], uniques = pd.factorize(news_train[col])\n        del uniques\n    \n    # Remove {} and '' from assetCodes column\n    news_train['assetCodes'] = news_train['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n    return news_train\n\nnews_train = preprocess_news(news_train)\n\nnews_train.head(4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"34c7e37cf6831cf6c568d5c71128cb7864e9667d"},"cell_type":"code","source":"# import gc\n# def unstack_asset_codes(news_train):\n#     codes = []\n#     indexes = []\n#     for i, values in news_train['assetCodes'].iteritems():\n#         #values=values.strip('{').strip('}').strip(\"'\").strip(\"'\")\n#         explode = values.split(\", \")\n#         codes.extend(explode)\n#         repeat_index = [int(i)]*len(explode)\n#         indexes.extend(repeat_index)\n        \n#     index_df = pd.DataFrame({'news_index': indexes, 'assetCode': codes})\n#     del codes, indexes\n#     gc.collect()\n#     return index_df\n\n# index_df = unstack_asset_codes(news_train)\n\n# index_df.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71a2d4df4b80edaa14b7a4ab9fa653905d7d13fa"},"cell_type":"code","source":"# def merge_news_on_index(news_train, index_df):\n#     news_train['news_index'] = news_train.index.copy()\n\n#     # Merge news on unstacked assets\n#     news_unstack = index_df.merge(news_train, how='left', on='news_index')\n#     news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)\n#     return news_unstack\n\n# news_unstack = merge_news_on_index(news_train, index_df)\n# del news_train, index_df\n# gc.collect()\n# news_unstack.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae7f0c618dc6b7ba54b9e60c155a04323e728232"},"cell_type":"code","source":"# news_unstack.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff7ea929db96ac923b946d9f3d58f8bdaa3e1620"},"cell_type":"code","source":"import gc\n\ndef group_news(news_frame):\n    news_frame['date'] = news_frame.time.dt.date  # Add date column\n    \n    aggregations = ['mean']\n    gp = news_frame.groupby(['assetCodes', 'date']).agg(aggregations)\n    gp.columns = pd.Index([\"{}_{}\".format(e[0], e[1]) for e in gp.columns.tolist()])\n    gp.reset_index(inplace=True)\n    # Set datatype to float32\n    float_cols = {c: 'float32' for c in gp.columns if c not in ['assetCodes', 'date']}\n    return gp.astype(float_cols)\n\nnews_agg = group_news(news_train)\n# del news_unstack; \ngc.collect()\nnews_agg.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d335865d4bf65c6f44292e9ad74f98a494fee7a"},"cell_type":"code","source":"news_agg.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a55808450f0eaaea8143b76196fc977b0c1173ac"},"cell_type":"code","source":"market_train['date'] = market_train.time.dt.date\n#news_unstack['date'] = news_unstack.time.dt.date\ndf = market_train.merge(news_agg, how='left', left_on=['date', 'assetCode'], \n                            right_on=['date', 'assetCodes'])\ndel market_train, news_agg\ngc.collect()\ndf.head(3)\ndf.shape\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e7f96822cd3d8b6edd3ab711905ae2ef4c83d85"},"cell_type":"code","source":"df = df.dropna(axis=0)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaedf636ec9a4f16315bad6a30837d6d00e72983"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccd443a305e306620cc8867b2f132be0d39cc936"},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"098653ccf2f7afb95651d3ed3fc196793b8d4176"},"cell_type":"code","source":"# def data_prep(market_train,news_unstack):\n#     market_train.time = market_train.time.dt.date\n#     #news_unstack.time = news_unstack.time.dt.hour\n#     news_unstack.sourceTimestamp= news_unstack.sourceTimestamp.dt.hour\n#     news_unstack.firstCreated = news_unstack.firstCreated.dt.date\n    \n#     #news_train['assetCodesLen'] = news_train['assetCodes'].map(lambda x: len(eval(x)))\n#     #news_unstack['assetCode'] = news_unstack['assetCode'].map(lambda x: eval(x))\n#     kcol = ['firstCreated', 'assetCode']\n#     news_unstack = news_unstack.groupby(kcol, as_index=False).mean()\n#     print(\"The shape after groub by is \",news_unstack.shape)\n#     print(\"The shape of market train before is \",market_train.shape)\n#     market_train = pd.merge(market_train, news_unstack, how='left', left_on=['time', 'assetCode'], right_on=['firstCreated', 'assetCode'])\n#     print(\"The shape of market train after is \",market_train.shape)\n#     lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n#     market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n    \n    \n#     market_train = market_train.dropna(axis=0)\n    \n#     return market_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53778545ce4b72e201540b4dcbcffd438779bd24"},"cell_type":"code","source":"# def data_prep(market_train,news_train):\n#     market_train.time = market_train.time.dt.date\n#     news_train.time = news_train.time.dt.hour\n#     news_train.sourceTimestamp= news_train.sourceTimestamp.dt.hour\n#     news_train.firstCreated = news_train.firstCreated.dt.date\n#     news_train['assetCodesLen'] = news_train['assetCodes'].map(lambda x: len(eval(x)))\n#     news_train['assetCodes'] = news_train['assetCodes'].map(lambda x: list(eval(x))[0])\n#     kcol = ['firstCreated', 'assetCodes']\n#     news_train = news_train.groupby(kcol, as_index=False).mean()\n#     market_train = pd.merge(market_train, news_train, how='left', left_on=['time', 'assetCode'], \n#                             right_on=['firstCreated', 'assetCodes'])\n#     lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n#     market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n    \n    \n#     market_train = market_train.dropna(axis=0)\n    \n#     return market_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed6327de812afeb4fbd1800e5063f2008ee43ba6"},"cell_type":"code","source":"#market_train = data_prep(market_train,news_unstack)\n\n#print(list(market_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5923a725069b266530a3f269919606aca50467f6"},"cell_type":"code","source":"up = df.returnsOpenNextMktres10 >= 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53862507c16c96b4f8dbddbe61f0360eefdd692f"},"cell_type":"code","source":"import pandas as pd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"328d8e47ae70b2621e0e6b03abe02f8f00528c3b"},"cell_type":"code","source":"fcol = [c for c in df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe41d37685aece46d76841546286ef4f66907cb6"},"cell_type":"code","source":"X = df[fcol].values\nup = up.values\nr = df.returnsOpenNextMktres10.values\n#print(market_train[fcol].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9816ed6c656d8f6e4e0eb63d5abbad7e56a200d7"},"cell_type":"code","source":"import numpy as np\nmins = np.min(X, axis=0)\nmaxs = np.max(X, axis=0)\nrng = maxs - mins\nX = 1 - ((maxs - X) / rng)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c35d299d28965f5e16a8092977609db181e0f78c"},"cell_type":"code","source":"assert X.shape[0] == up.shape[0] == r.shape[0] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42073c426c5827f03cb13c845d2e36ff1f76bcd0"},"cell_type":"code","source":"X_train, X_test, up_train, up_test, r_train, r_test\\\n= model_selection.train_test_split(X, up, r, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42ef9f4bb22cf61fcbebb44d90aacbc693204c3a"},"cell_type":"code","source":"# from sklearn.decomposition import PCA\n# print(\"shape before pca is \",X_train.shape)\n# Data_pca= PCA(n_components=10).fit(X_train)\n# X_train_pca= Data_pca.transform(X_train)\n# print(\"shape after pca is \",X_train_pca.shape)\n\n# X_test_pca= Data_pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a83e56932855dc1c9a8a24d9e6db76e31c92edfe"},"cell_type":"code","source":"# from sklearn.ensemble import AdaBoostClassifier\n# from sklearn.metrics import accuracy_score\n# BoostModel= AdaBoostClassifier(n_estimators=300)\n# BoostModel.fit(X_train,up_train)\n# print(BoostModel.score(X_test,up_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04c44699034e3a8cda6f8553ec038a21bc729a32"},"cell_type":"code","source":"# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n# LDAmodelFitted= LinearDiscriminantAnalysis().fit(X_train, up_train)\n# print(LDAmodelFitted.score(X_test,up_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7648a16267afd9cb43c3e5416aa2f63df3ebc52e"},"cell_type":"code","source":"# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n# QDAmodelFitted= QuadraticDiscriminantAnalysis().fit(X_train, up_train)\n# print(QDAmodelFitted.score(X_test,up_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40f7cc8d994198ace0dd5950a43b7ebe7a9f314a"},"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n\n# LogRegModel= LogisticRegression( )\n# LogRegModel.fit(X_train,up_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf00afca852fe2488394bcd2bae930809e966b8b"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n#LogRegModel.score(X_test,up_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d6625c246e0b41022e9ff4cf4dbd344d1909051"},"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.metrics import accuracy_score\n# knn=KNeighborsClassifier(n_neighbors=100) \n# knn.fit(X_train, up_train)\n# knn.score(X_test,up_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ab05c869335d2d54c92db299ad13d25ebf7077"},"cell_type":"code","source":"from xgboost import XGBClassifier\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27ca6ad3a339944a0428662ce342e8ea6c8dfe0b"},"cell_type":"code","source":"xgb_up = XGBClassifier(n_jobs=4,n_estimators=250,max_depth=8,eta=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea6e76cb26c2e063a633f9d92ea1a667c16f39a6"},"cell_type":"code","source":"xgb_up.fit(X_train,up_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77418fff01529be199ec436dca89986692fdab8f"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n#accuracy_score(xgb_up.predict(X_test),up_test)\nxgb_up.score(X_test,up_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e67e1cd87ed06ffefb2e3c4660daa40a9d0c7519"},"cell_type":"code","source":"# t = time.time()\n# print('Fitting Up')\n# xgb_up.fit(X_train,up_train)\n# print(f'Done, time = {time.time() - t}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c883119fb6274f3dd8066cacd28751b42f4c917e"},"cell_type":"code","source":"# from sklearn.metrics import accuracy_score\n# #accuracy_score(xgb_up.predict(X_test),up_test)\n# xgb_up.score(X_test,up_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3594186460ae52871ad6259ee013c70bb5ffef12"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a918074059f8acdbaceab456d227555176bd0b8","scrolled":true},"cell_type":"code","source":"n_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in (days):\n    n_days +=1\n    print(n_days,end=' ')\n    t = time.time()\n    #market_obs_df = data_prep(market_obs_df, news_obs_df)\n    news_obs_df = preprocess_news(news_obs_df)\n#   index_df = unstack_asset_codes(news_obs_df)\n#   news_unstack = merge_news_on_index(news_obs_df, index_df)\n    news_agg = group_news(news_obs_df)\n    \n    market_obs_df['date'] = market_obs_df.time.dt.date\n    df = market_obs_df.merge(news_agg, how='left', left_on=['date', 'assetCode'], \n                            right_on=['date', 'assetCodes'])\n    del market_obs_df, news_agg\n    gc.collect()\n\n    \n    df = df[df.assetCode.isin(predictions_template_df.assetCode)]\n    X_live = df[fcol].values\n    X_live = 1 - ((maxs - X_live) / rng)\n    prep_time += time.time() - t\n    \n    t = time.time()\n    lp = xgb_up.predict_proba(X_live)\n    prediction_time += time.time() -t\n    \n    t = time.time()\n    confidence = 2* lp[:,1] -1\n    preds = pd.DataFrame({'assetCode':df['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c457cc926f6dfcb7bb8aedcb92347e50394d56d"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04298fac3a9014d9289fbe1733f855e4823c3567"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}